---
typora-root-url: D:\typora图片总
---

# 深度学习

## 一、ROC曲线和PR曲线

### 1、度量

假定下面一个例子，假定在10000个样本中有100个正样本，其余为负样本，其在分类器下的混淆矩阵(confusion matrix)为：

![](/20170113145843181.png)

则，我们定义：

1. TN / True Negative: case was negative and predicted negative 
2. TP / True Positive: case was positive and predicted positive 
3. FN / False Negative: case was positive but predicted negative 
4. FP / False Positive: case was negative but predicted positive

**则定义一下度量**：

真正率(true positive rate,TPR)或灵敏度(sensitivity)，定义为被模型正确预测的正样本的比例：

​                                                          $TPR=\frac{TP}{TP+FN}​$

真负率(true negative rate,TFR)或特指度(specificity)，定义为被模型正确预测的负样本的比例：

​                                                          $TPR=\frac{TN}{TN+FP}$

同理，假正率(false positive rate,FPR) 

​                                                          $FPR=\frac{FP}{TN+FP}$

假负率(flase negative rate,FNR) 

​                                                          $FNR=\frac{FN}{TP+FN}$

**重要的度量：**

- **precision**(精度)，其与accuracy感觉中文翻译一致，周志华老师的书中称为：查准率:

​                                                            $p=\frac{TP}{TP+FP}$

- **recall**(召回率),周志华老师的书中称为查全率，其又与真正率一个公式： 

​                                                            $r=\frac{TP}{TP+FN}​$

​       **精度**是确定分类器中断言为正样本的部分其实际中属于正样本的比例，精度越高则假的正例就越低，**召回率**则是被分类器正确预测的正样本的比例。

两者是一对矛盾的度量，其可以合并成令一个度量，F1度量： 

​                                                      $F1=\frac{2rp}{r+p}=\frac{2*TP}{2*TP+FP+FN}$

如果对于precision和recall的重视不同，则一般的形式：

​                                                      $F_\beta=\frac{(1+\beta^2)rp}{\beta^2*p+r}$

可以从公式中看到β=1则退化成F1。

β>1则recall有更大影响，反之则precision更多影响。

**（**注：假定在10000个样本中有100个正样本，其余为负样本：

在预测结果中，我预测9800个是负样本，200个是正样本

精度：在我预测的200个正样本中，有60个预测对了，另外140个预测错了，则精度为60/200=0.3

召回率：实际上样本中一共有100个正样本，我预测出了其中的60个，则召回率为60/100=0.6

举例，要将坏人抓到监狱，精度看的是，被抓进监狱的人，到底有多少是真的坏人；召回率是看，我最终将多大比例的坏人抓起来了。

如果我只抓了两个人进监狱，他们都是坏人，此时，精度很高，但是召回率很低，因为还有很多坏人没抓起来；

反之，我抓了很多人进了监狱，其中包括很多坏人，此时召回率很高，但精度很低；

所以，要同时考虑精度和召回率。**）**



### 2、ROC曲线

**ROC(Receiver Operating Characteristic)**: 是一条曲线，由FPR和TPR的点连成。横轴是FPR，纵轴是TPR  

**AUC(Area Under the Curve)**：ROC的曲线面积就是AUC值。AUC主要用于衡量二分类问题中机器学习算法性能或者泛化能力。

![](/20180815154940692.png)

ROC曲线重点了解下这几个节点：

（0,1）点：代表FPR=0,TPR=1； 最好的情况，所有正样本都被正确的预测了，并且没有负样本被人为是正样本。

（1,0）点：代表FPR=1,TPR=0；最坏的情况，表明所有的正样本都被错误的认为是负样本

（0,0）点：代表FPR=0,TPR=0;分类器将所有的样本都判定为负样本

（1,1）点：代表FPR=1,TPR=1；分类器将所有的样本都判定为正样本

 如上图，有一条红色的虚线，y=x ，这条曲线的面积为0.5 ，这里是代表的如果是随机猜测的话，AUC=0.5.如果我们得到的ROC曲线在y=x下面，AUC<0.5,则表明分类器不合格，还不如乱猜测。

在实际中由于侧重的点不同，所以我们需要明白侧重在哪，如果在实际中结果重在覆盖，我们应该更加注重True Positive高，如果是重在准确，我们则应该更加注重False Positive低

那么怎么通过ROC曲线来判断True Positive和False Positive呢？ 这里我们如果看到曲线越往左上凸越好（AUC越大越好），这样得到的True Positive 就越高，对应的False Positive越低

上图来自于我做的逻辑回归分类，最终得到的模型AUC=0.99。

![](/20170113155954155.png)

ROC曲线有助于比较不同分类器的相对性能，当FPR小于0.36时M1好于M2，而大于0.36是M2较好。 
ROC曲线小猫的面积为AUC(area under curve)，其面积越大则分类的性能越好，理想的分类器auc=1。

### 3、PR曲线

**PR曲线：** 是由精确率和召回率的点连成的线，横轴为Recall ,纵轴为Precision，

在PR曲线中越右上凸越好，PR想要Precision 和Recall同时高

![](/20180815143918432.png)

- **AP**(平均精度)：PR曲线之下的面积，是精度precision对召回率recall的积分

- **mAP**:所有类别的平均精度求和除以所有类别，即数据集中所有类的平均精度的平均值

### 4、如何选择ROC、PR

下面节选自：[What is the difference between a ROC curve and a precision-recall curve? When should I use each?](https://www.quora.com/What-is-the-difference-between-a-ROC-curve-and-a-precision-recall-curve-When-should-I-use-each)

Particularly, if true negative is not much valuable to the problem, or negative examples are abundant. Then, PR-curve is typically more appropriate. For example, if the class is highly imbalanced and positive samples are very rare, then use PR-curve. One example may be fraud detection, where non-fraud sample may be 10000 and fraud sample may be below 100. 

In other cases, ROC curve will be more helpful.

其说明，如果是不平衡类，正样本的数目非常的稀有，而且很重要，比如说在诈骗交易的检测中，大部分的交易都是正常的，但是少量的非正常交易确很重要。

Let’s take an example of fraud detection problem where there are 100 frauds out of 2 million samples. 
Algorithm 1: 90 relevant out of 100 identified 
Algorithm 2: 90 relevant out of 1000 identified

Evidently, algorithm 1 is more preferable because it identified less number of false positive. 
In the context of ROC curve, 
Algorithm 1: TPR=90/100=0.9, FPR= 10/1,999,900=0.00000500025 
Algorithm 2: TPR=90/100=0.9, FPR=910/1,999,900=0.00045502275 
The FPR difference is 0.0004500225

For PR, Curve 
Algorithm 1: precision=0.9, recall=0.9 
Algorithm 2: Precision=90/1000=0.09, recall= 0.9 
Precision difference= 0.81

可以看到在正样本非常少的情况下，PR表现的效果会更好。

### 5、如何绘制ROC曲线

为了绘制ROC曲线，则分类器应该能输出连续的值，比如在**逻辑回归分类器**中，其以概率的形式输出，可以设定阈值大于0.5为正样本，否则为负样本。因此设置不同的阈值就可以得到不同的ROC曲线中的点。 
下面给出具体的实现过程：

![](/20170113163432528.png)

下面给出[sklearn中的实现过程](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py)：

```python
print(__doc__)

import numpy as np
from scipy import interp
import matplotlib.pyplot as plt
from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import StratifiedKFold

###############################################################################
# Data IO and generation

# import some data to play with
iris = datasets.load_iris()
X = iris.data
y = iris.target
X, y = X[y != 2], y[y != 2]
n_samples, n_features = X.shape

# Add noisy features
random_state = np.random.RandomState(0)
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]

###############################################################################
# Classification and ROC analysis

# Run classifier with cross-validation and plot ROC curves
cv = StratifiedKFold(n_splits=6)

# 注意这里的应该改为probability=True以概率形式输出
classifier = svm.SVC(kernel='linear', probability=True,
                     random_state=random_state)

mean_tpr = 0.0
mean_fpr = np.linspace(0, 1, 100)

colors = cycle(['cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange'])
lw = 2

i = 0
# k折交叉验证
for (train, test), color in zip(cv.split(X, y), colors):
    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])
    # Compute ROC curve and area the curve
    #　注意这里返回的阈值，以区分正负样本的阈值
    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])
    ＃　进行插值
    mean_tpr += interp(mean_fpr, fpr, tpr)
    mean_tpr[0] = 0.0
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=lw, color=color,
             label='ROC fold %d (area = %0.2f)' % (i, roc_auc))

    i += 1
plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k',
         label='Luck')

mean_tpr /= cv.get_n_splits(X, y)
mean_tpr[-1] = 1.0
mean_auc = auc(mean_fpr, mean_tpr)
plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--',
         label='Mean ROC (area = %0.2f)' % mean_auc, lw=lw)

plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
```

运行的结果如下图所示：

![](/20170113163901920.png)

### 6、如何绘制PR曲线

```python
#coding:utf-8
import matplotlib
matplotlib.use("Agg")
import numpy as np
import matplotlib.pyplot as plt
plt.figure(1) # 创建图表1
plt.title('Precision/Recall Curve')# give plot a title
plt.xlabel('Recall')# make axis labels
plt.ylabel('Precision')
 
#x、y都是列表，里面存的分别是recall和precision
#传参得到或读取文件得到无所谓
x=[]
y=[]
f=open('eval.txt','r')
lines=f.readlines()
for i in range(len(lines)/3):
    y.append(float(lines[3*i].strip().split(':')[1]))
    x.append(float(lines[3*i+1].strip().split(':')[1]))
f.close()
plt.figure(1)
plt.plot(x, y)
plt.show()
plt.savefig('p-r.png')
```

![](/20161223200222355.png)



## 二、神经网络核心概念

#### 1、batch normalize批标准化





## 三、经典神经网络模型对比

### 1、LeNet-5



### 2、AlexNet



### 3、VGG



### 4、GoogLeNet



### 5、ResNet、ResNeXt



## 注：比较好的链接

1、关于AP PR曲线计算的理解（内附代码，生肉，英文）：

[https://github.com/rafaelpadilla/Object-Detection-Metrics#create-the-ground-truth-files](https://github.com/rafaelpadilla/Object-Detection-Metrics%23create-the-ground-truth-files)

2、关于数据增强的奇淫技巧：https://www.zhihu.com/question/35339639

3、一篇超级全的数据增强博客：https://blog.csdn.net/daniaokuye/article/details/78535879

4、YJango的卷积神经网络介绍：https://zhuanlan.zhihu.com/p/27642620

5、关于batch normalization的理解：https://www.cnblogs.com/guoyaohua/p/8724433.html

6、各类归一化方法的总结及代码：https://blog.csdn.net/liuxiao214/article/details/81037416

7、各种标注工具：https://blog.csdn.net/u012426298/article/details/80519158

8、pytorch教程：

github上7k星的pytorch教程：https://github.com/yunjey/pytorch-tutorial

pytorch 0.4中文文档：https://ptorch.com/docs/8/

pytorch官方教程翻译：

<https://mp.weixin.qq.com/s?__biz=Mzg5NzAxMDgwNg==&mid=2247484041&idx=1&sn=a3580ff29d34556a3eb26ddba8b01e29&chksm=c0791f90f70e9686fb7afec2a3f5c3aeb2694fd054c7a45fb51829e9e85c7aa5c2b0580bc3be&mpshare=1&scene=23&srcid=0109XWDDUIVRlU1lezhBKF4t#rd>

Pytorch入门与实践：https://github.com/chenyuntc/pytorch-book

Pytorch模型训练实用教程：https://github.com/tensor-yu/PyTorch_Tutorial

9、github上2w+星的tensorflow教程：

<https://github.com/aymericdamien/TensorFlow-Examples>

10、经典论文原文及其中文对照翻译： Alexnet   VGG  Resnet  GoogLenet  BN-GoogLenet  Inception-v3  SENet

YOLO  SSD  YOLO9000  Deformable-ConvNets  Faster R-CNN  R-FCN  FPN CRNN  CTPN

https://github.com/jiajunhua/SnailTyan-deep-learning-papers-translation

11、数据增强代码：https://github.com/aleju/imgaug

12、手写数字识别：https://blog.csdn.net/qq_33000225/article/details/73123880 

13、keras搭建cnn实现手写数字识别：https://www.jianshu.com/p/b22e708a3f37 

14、关于残差网络的解析：https://blog.csdn.net/rogerchen1983/article/details/79353972

15、 深度学习相关面试考点总结：https://zhuanlan.zhihu.com/p/48374690 

16、HyperLPR：深度学习高性能车牌识别https://github.com/zeusees/HyperLPR

17、服装开源数据集（6w数据集1w测试集）：

<https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion>

18、服装识别开源实例（看到新的会再补充，这部分最近有可能会关注一下）：

<https://github.com/KaiJin1995/fashionAI2018/tree/master>

<https://github.com/zccoder/fashionAI>

<https://github.com/team79/Tianchi_FashionAI_ClothingLabelRecognition>

19、一个模型可视化工具（支持多种主流框架如PyTorch\Caffe\TensorFlow）：

https://github.com/lutzroeder/netron











